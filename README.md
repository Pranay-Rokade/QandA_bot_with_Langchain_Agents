# Advanced Q&A Bot with LangChain Agents and Multi-Source Retrieval

This project showcases how to build an **intelligent agent-powered Q&A bot** that can answer questions using data from multiple sources such as:

- ğŸŒ Wikipedia
- ğŸ“š ArXiv research papers
- ğŸ“„ LangSmith documentation via web scraping + vector search (RAG)

LangChain's **agent** system, paired with tool integration (`QueryRun`, `RetrieverTool`, etc.), allows dynamic tool selection and natural-language-driven orchestration.

---

## ğŸ§  Core Concepts Explored

| Concept | Description |
|--------|-------------|
| ğŸ§° `QueryRun` | Tool to fetch answers using APIs like Wikipedia or ArXiv |
| ğŸ§© `APIWrapper` | Wraps external APIs for integration with LangChain tools |
| ğŸ“š `RetrieverTool` | Wraps a vector retriever (RAG) into a tool usable by agents |
| ğŸ§  `AgentExecutor` | Coordinates between tools and the LLM to generate answers |
| âš™ï¸ `create_openai_tools_agent` | Combines LLM, tools, and prompt into an autonomous agent |
| ğŸ” `FAISS` + `HuggingFaceEmbeddings` | Used for RAG over LangSmith docs |

---

## ğŸ“ Project Structure

```

.
â”œâ”€â”€ .env                             # API Keys
â”œâ”€â”€ agents.ipynb        # Full notebook implementation
â”œâ”€â”€ Colon.pdf, other docs           # (Optional) supporting PDFs
â””â”€â”€ README.md

````

---

## ğŸ”§ Setup Instructions

### 1. Install Dependencies

```bash
pip install langchain langchain-community langchainhub faiss-cpu sentence-transformers python-dotenv
````

### 2. Add `.env` File

```env
GROQ_API_KEY=your_groq_api_key
```

---

## ğŸ”Œ Data Sources & Tool Setup

### ğŸ“š LangSmith Docs (RAG)

* Loaded with `WebBaseLoader`
* Chunked using `RecursiveCharacterTextSplitter`
* Embedded using `HuggingFaceEmbeddings`
* Stored in `FAISS` and exposed via `RetrieverTool`

### ğŸŒ Wikipedia & ArXiv Integration

```python
from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper
from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun
```

Both are converted to tools for the agent to dynamically call.

---

## ğŸ¤– LLM & Agent Setup

### LLM Configuration (Groq - LLaMA3)

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI()
```

### Prompt & Agent Creation

```python
from langchain import hub
prompt = hub.pull("hwchase17/openai-functions-agent")

from langchain.agents import create_openai_tools_agent
agent = create_openai_tools_agent(llm, tools, prompt)
```

### Final Agent Executor

```python
from langchain.agents import AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

---

## ğŸ§ª Example Queries

```python
agent_executor.invoke({"input": "Tell me about Langsmith"})
agent_executor.invoke({"input": "What's the paper 1605.08386 about?"})
agent_executor.invoke({"input": "What is React?"})
```

Agent will:

* Use the correct tool (Wikipedia, ArXiv, LangSmith retriever) based on input
* Retrieve relevant data
* Generate coherent answers

---

## âœ… What You Learned

* âœ… How to build a **multi-source retrieval system** for Q\&A
* âœ… Use of `APIWrapper` and `QueryRun` for external data integration
* âœ… Vectorization + FAISS for RAG-based document QA
* âœ… Creating LangChain agents with dynamic tool execution
* âœ… Prompt-driven tool selection and multi-hop reasoning

---

## ğŸ”® Next Steps

* Add caching and persistent vector DBs (e.g., Chroma, Weaviate)
* Integrate memory for multi-turn conversations
* Deploy via `FastAPI` or `LangServe`
* Connect to frontend with Streamlit or React

---

## ğŸ™Œ Credits

* [LangChain Docs](https://docs.langchain.com/)
* [Groq API](https://console.groq.com/)
* [ArXiv API](https://arxiv.org/help/api/)
* [Wikipedia API](https://www.mediawiki.org/wiki/API:Main_page)

---

## ğŸš€ Build Your Own Knowledge-Integrated Agents with LangChain Today!
